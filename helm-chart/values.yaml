# Global settings
global:
  namespace: litellm

# LiteLLM Gateway configuration
litellm:
  image:
    repository: ghcr.io/berriai/litellm
    tag: "main-latest"
    pullPolicy: Always
  
  replicaCount: 1
  
  # Resource limits and requests
  resources:
    limits:
      memory: "4Gi"
      cpu: "2000m"
    requests:
      memory: "2Gi"
      cpu: "1000m"
  
  # Environment variables
  env:
    STORE_MODEL_IN_DB: "True"
    LITELLM_MASTER_KEY: "sk-1234"
    UI_USERNAME: "admin"
    UI_PASSWORD: "admin123"
  
  # Configuration
  config:
    model_list:
      - model_name: gemini-pro
        litellm_params:
          model: vertex_ai/gemini-pro
          vertex_project: "pdlgcpcloud"
          vertex_location: "us-central1"
      - model_name: gemini-pro-vision
        litellm_params:
          model: vertex_ai/gemini-pro-vision
          vertex_project: "pdlgcpcloud"
          vertex_location: "us-central1"
      - model_name: gemini-flash
        litellm_params:
          model: vertex_ai/gemini-2.5-flash-lite
          vertex_project: "pdlgcpcloud"
          vertex_location: "us-central1"
    
    general_settings:
      master_key: "sk-1234"
      database_url: ""
      ui_username: "admin"
      ui_password: "admin123"
    
    litellm_settings:
      drop_params: true
      set_verbose: false

  # Service configuration
  service:
    type: LoadBalancer
    port: 80
    targetPort: 4000
    annotations: {}

  # Health checks
  healthCheck:
    enabled: true
    livenessProbe:
      httpGet:
        path: /health
        port: 4000
      initialDelaySeconds: 60
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      httpGet:
        path: /health
        port: 4000
      initialDelaySeconds: 30
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3

  # Horizontal Pod Autoscaler
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

# PostgreSQL configuration
postgresql:
  enabled: true
  image:
    repository: postgres
    tag: "15"
    pullPolicy: IfNotPresent
  
  # Database credentials
  auth:
    database: "litellm"
    username: "litellm"
    password: "password"
  
  # Resource limits
  resources:
    limits:
      memory: "1Gi"
      cpu: "500m"
    requests:
      memory: "512Mi"
      cpu: "250m"
  
  # Persistence
  persistence:
    enabled: true
    size: "10Gi"
    storageClass: ""
    accessMode: ReadWriteOnce
  
  # Service
  service:
    type: ClusterIP
    port: 5432

# Vertex AI configuration
vertexAI:
  projectId: "pdlgcpcloud"
  serviceAccountKey: "VertexAiKey.json"
  location: "us-central1"

# Security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Pod annotations
podAnnotations: {}

# Pod labels
podLabels: {}